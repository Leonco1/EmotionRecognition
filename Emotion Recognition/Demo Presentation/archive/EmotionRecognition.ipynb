{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851636e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be35090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c2dfe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datadirectory=\"train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classes=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in Classes:\n",
    "    path=os.path.join(Datadirectory,category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=cv2.imread(os.path.join(path,img))\n",
    "        plt.imshow(cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=224\n",
    "new_array=cv2.resize(img_array,(img_size,img_size))\n",
    "plt.imshow(cv2.cvtColor(new_array,cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ada91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "\n",
    "# def delete_half_of_files_in_folders(parent_folder):\n",
    "#     for folder_name in range(7):  # Assuming 7 folders from 0 to 6\n",
    "#         folder_path = os.path.join(parent_folder, str(folder_name))\n",
    "\n",
    "#         # Check if the folder exists\n",
    "#         if os.path.exists(folder_path):\n",
    "#             # Get a list of all files in the folder\n",
    "#             files = os.listdir(folder_path)\n",
    "\n",
    "#             # Calculate the number of files to delete (half of the total)\n",
    "#             num_files_to_delete = len(files) // 2\n",
    "\n",
    "#             # Randomly select files to delete\n",
    "#             files_to_delete = random.sample(files, num_files_to_delete)\n",
    "\n",
    "#             # Iterate through selected files and delete them\n",
    "#             for file_name in files_to_delete:\n",
    "#                 file_path = os.path.join(folder_path, file_name)\n",
    "#                 os.remove(file_path)\n",
    "#                 print(f\"Deleted: {file_path}\")\n",
    "\n",
    "# # Specify the path to the parent folder containing folders 0 to 6\n",
    "# parent_folder_path = r'C:\\Users\\Leonid\\Desktop\\Seminarska\\archive\\train'\n",
    "\n",
    "# # Call the function to delete half of the files in each folder\n",
    "# delete_half_of_files_in_folders(parent_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17276f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "\n",
    "def create_training_Data():\n",
    "    for category in Classes:\n",
    "        path=os.path.join(Datadirectory,category)\n",
    "        class_num=Classes.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img))\n",
    "                new_arrays=cv2.resize(img_array,(img_size,img_size))\n",
    "                training_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ed670",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_Data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23134a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d60c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5e4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "X=np.array(X).reshape(-1,img_size,img_size,3)\n",
    "#convert to 4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa376ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "X=X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8843a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d643f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.applications.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47480ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ba7a9cd",
   "metadata": {},
   "source": [
    "#Transfer learning \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input=model.layers[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f396b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output=model.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45fc162",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output=layers.Dense(128)(base_output)\n",
    "final_output=layers.Activation('relu')(final_output)#ACTVATION FUNC\n",
    "final_output=layers.Dense(64)(final_output)\n",
    "final_output=layers.Activation('relu')(final_output)\n",
    "final_output=layers.Dense(7,activation='softmax')(final_output)#IMAME 7 FUNCKII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eafaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=keras.Model(inputs=base_input,outputs=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad027952",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36959b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82077c27-9e50-4aa7-85bb-20b52b45ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "\n",
    "# print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model.fit(X,Y,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06fe69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model.save(\"final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=cv2.imread(\"happy_boy.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501bf18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565c758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f84d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#face detection algorithm  \n",
    "face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8689784",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=tf.keras.models.load_model(\"final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05126f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces=face_cascade.detectMultiScale(gray,1.1,4)\n",
    "for x,y,w,h in faces:\n",
    "    roi_gray=gray[y:y+h,x:x+w]\n",
    "    ro_color=frame[y:y+h,x:x+w]\n",
    "    cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    facess=face_cascade.detectMultiScale(roi_gray)\n",
    "    if len(facess)==0:\n",
    "        print(\"Face not detected\")\n",
    "    else:\n",
    "        for(ex,ey,ew,eh) in facess:\n",
    "            face_roi=roi_color[ey:ey+eh,ex:ex+ew]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa615b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(face_roi,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image=cv2.resize(face_roi,(224,224))\n",
    "final_image=np.expand_dims(final_image,axis=0)\n",
    "final_image=final_image/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions=new_model.predict(final _image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1417a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61787800",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=np.argmax(Predictions)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predicted==0:\n",
    "     print(\"angry\")\n",
    "elif predicted==1:\n",
    "    print(\"disgust\")\n",
    "elif predicted==2:\n",
    "    print(\"fear\")\n",
    "elif predicted==3:\n",
    "    print(\"happy\")\n",
    "elif predicted==4:\n",
    "    print(\"neutral\")\n",
    "elif predicted==5:\n",
    "    print(\"sad\")\n",
    "else: print(\"suprise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4953eb",
   "metadata": {},
   "source": [
    "# za video camera\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path='haarcascade_frontalface_default.xml'\n",
    "# font_scale=1.5\n",
    "# font=cv2.FONT_HERSHEY_PLAIN\n",
    "# rectangle_bgr=(255,255,255)\n",
    "# img=np.zeros((500,500))\n",
    "# text=\"Emotion\"\n",
    "# (text_width,text_height)=cv2.getTextSize(text,font,fontScale=font_scale,thickness=1)[0]\n",
    "# text_offset_x=10\n",
    "# text_offset_y=img.shape[0]-25\n",
    "# box_coords=((text_offset_x,text_offset_y),(text_offset_x+text_width+2,text_offset_y-text_height-2))\n",
    "# cv2.rectangle(img,box_coords[0],box_coords[1],rectangle_bgr,cv2.FILLED)\n",
    "# cv2.putText(img,text,(text_offset_x,text_offset_y),font,fontScale=font_scale,color=(0,0,0),thickness=1)\n",
    "\n",
    "# cap=cv2.VideoCapture(1)\n",
    "# if not cap.isOpened():\n",
    "#     cap=cv2.VideoCapture(0)\n",
    "# if not cap.isOpened():\n",
    "#     raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# while True:\n",
    "#     ret,frame=cap.read()\n",
    "#     face_Cascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "#     gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "#     faces=face_Cascade.detectMultiScale(gray,1.1,4)\n",
    "#     for x,y,w,h in faces:\n",
    "#         roi_gray=gray[y:y+h,x:x+w]\n",
    "#         roi_color=frame[y:y+h,x:x+w]\n",
    "#         cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "#         facess=face_Cascade.detectMultiScale(roi_gray)\n",
    "#         if len(facess)==0:\n",
    "#             print(\"Face not detected\")\n",
    "#         else:\n",
    "#             for(ex,ey,ew,eh) in facess:\n",
    "#                 face_roi=roi_color[ey:ey+eh,ex:ex+ew]\n",
    "#     final_image=cv2.resize(face_roi,(224,224))\n",
    "#     final_image=np.expand_dims(final_image,axis=0)\n",
    "#     final_image=final_image/255.0\n",
    "#     font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     Predictions=new_model.predict(final_image)\n",
    "#     font_scale=1.5\n",
    "#     font=cv2.FONT_HERSHEY_PLAIN\n",
    "#     predict=np.argmax(Predictions)\n",
    "#     if predict==0:\n",
    "#         status=\"Angry\"\n",
    "#         x1,y1,w1,h1=0,0,175,175\n",
    "#         cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "#         cv2.putText(frame,status,(x1+int(w1/10),y1+int(h1/2)),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "#         cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "#         cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "#     elif predict==1:\n",
    "#         status=\"Disgust\"\n",
    "#         x1,y1,w1,h1=0,0,175,175\n",
    "#         cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "#         cv2.putText(frame,status,(x1+int(w1/10),y1+int(h1/2)),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "#         cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "#         cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "#     elif predict==2:\n",
    "#         status=\"Fear\"\n",
    "#         x1,y1,w1,h1=0,0,175,175\n",
    "#         cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "#         cv2.putText(frame,status,(x1+int(w1/10),y1+int(h1/2)),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "#         cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "#         cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "#     elif predict==3:\n",
    "#         status=\"Happy\"\n",
    "#         x1,y1,w1,h1=0,0,175,175\n",
    "#         cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "#         cv2.putText(frame,status,(x1+int(w1/10),y1+int(h1/2)),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "#         cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "#         cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "#     elif predict==4:\n",
    "#         status=\"Sad\"\n",
    "#         x1,y1,w1,h1=0,0,175,175\n",
    "#         cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "#         cv2.putText(frame,status,(x1+int(w1/10),y1+int(h1/2)),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "#         cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "#         cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "#     elif predict==5:\n",
    "#         status=\"Suprise\"\n",
    "#         x1,y1,w1,h1=0,0,175,175\n",
    "#         cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "#         cv2.putText(frame,status,(x1+int(w1/10),y1+int(h1/2)),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "#         cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "#         cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "#     else:\n",
    "#         status=\"Neutral\"\n",
    "#         x1,y1,w1,h1=0,0,175,175\n",
    "#         cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "#         cv2.putText(frame,status,(x1+int(w1/10),y1+int(h1/2)),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "#         cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "#         cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0))\n",
    "        \n",
    "#     cv2.imshow(\"Face Emotion Recognition\",frame)\n",
    "#     if(cv2.waitKey(2)& 0xFF==ord('q')):\n",
    "#         break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6b1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
